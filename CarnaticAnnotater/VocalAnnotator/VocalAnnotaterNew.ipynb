{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64d87f85",
   "metadata": {},
   "source": [
    ".\\.venv\\Scripts\\Activate.ps1      "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e951fd",
   "metadata": {},
   "source": [
    "Cell 0: Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9072cf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Optional, Tuple, Union\n",
    "import random\n",
    "import json\n",
    "import ast\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "from fastdtw import fastdtw\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import IPython.display as ipd\n",
    "carnatic_functions_path = r\"C:\\Desktop\\Python\\Audio Signal Processing\\CarnaticAnnotater\"\n",
    "sys.path.append(carnatic_functions_path)\n",
    "from carnatic_functions import (\n",
    "    # --- CONFIGURATION ---\n",
    "    AUDIO_CONFIG,\n",
    "    CREPE_CONFIG,\n",
    "    CLUSTERING_CONFIG,\n",
    "    CARNATIC_RATIOS,\n",
    "\n",
    "    # --- UTILITY FUNCTIONS ---\n",
    "    get_data_paths,\n",
    "    get_closest_note,\n",
    "    get_closest_frequency,\n",
    "    clean_np_float_list,\n",
    "    interpolate_list,\n",
    "\n",
    "    # --- PHASE 1: DATA PREP & INITIAL CLUSTERING ---\n",
    "    process_audio_directory,\n",
    "    add_normalized_frequency_column,\n",
    "    perform_multistage_clustering,\n",
    "\n",
    "    # --- PHASE 2: SECONDARY CLUSTERING ---\n",
    "    recluster_with_dtw,\n",
    "    recluster_with_pca,\n",
    "\n",
    "    # --- ANALYSIS & VISUALIZATION ---\n",
    "    evaluate_clustering_results,\n",
    "    label_cluster,\n",
    "    cluster_curve,\n",
    "    play_and_plot_cluster,\n",
    "    play_and_plot_secondary_cluster\n",
    ")\n",
    "audio_dir = r\"C:\\Desktop\\Python\\Audio Signal Processing\\CarnaticAnnotater\\Mayamalavagowlai_Vocals\"\n",
    "carva_csv_path = r\"C:\\Desktop\\Python\\Audio Signal Processing\\CarnaticAnnotater\\VocalAnnotator\\data\\Mayamalavagowlai\\carva_Mayamalavagowlai.csv\"\n",
    "print(\"‚úÖ All libraries and functions imported successfully!\")\n",
    "print(\"üéµ Ready to analyze Carnatic music!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f14886c",
   "metadata": {},
   "source": [
    "Cell 1: Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6f004b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    \"initial_window_size\": 60,\n",
    "    \"decay_size\": 2,\n",
    "    \"min_window_size\": 20,\n",
    "    \"hop_factor\": 5,\n",
    "    \"outlier_threshold\": 2,\n",
    "    \"similarity_threshold\": 0.3,\n",
    "    \"pca_components\": 15,\n",
    "    \"second_phase_window_size\": 20,\n",
    "    \"similarity_threshold_secondary\": 0.7,\n",
    "    \"pca_components_secondary\": 10\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d30fb7",
   "metadata": {},
   "source": [
    "Cell 2: Crepe Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6d20fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_audio_directory(audio_dir)\n",
    "add_normalized_frequency_column(audio_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0128120",
   "metadata": {},
   "source": [
    "Cell 3: Dynamic Decay Clustering (Round 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2154662c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç STEP 3: Performing multi-stage clustering...\")\n",
    "perform_multistage_clustering(audio_dir, CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6118b262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cluster_curve(audio_dir: str, song_index: int,\n",
    "#                   carva_path: Optional[str] = None,\n",
    "#                   clusters_to_plot: Optional[Union[int, List[int]]] = None):\n",
    "\n",
    "#     raaga_name = Path(audio_dir).name\n",
    "#     if raaga_name.endswith('_Vocals'):\n",
    "#         raaga_name = raaga_name.replace('_Vocals', '')\n",
    "\n",
    "#     paths = get_data_paths(raaga_name)\n",
    "\n",
    "#     try:\n",
    "#         master_df = pd.read_csv(paths[\"master_csv\"])\n",
    "\n",
    "#         if carva_path:\n",
    "#             carva_df = pd.read_csv(carva_path)\n",
    "#         else:\n",
    "#             carva_df = pd.read_csv(paths[\"carva_csv\"])\n",
    "\n",
    "#     except FileNotFoundError as e:\n",
    "#         print(f\"‚ùå Required data file not found: {e}\")\n",
    "#         return\n",
    "\n",
    "#     song_data = master_df[master_df[\"Index\"] == song_index]\n",
    "#     clustered_segments = carva_df[carva_df[\"Index\"] == song_index]\n",
    "\n",
    "#     if song_data.empty:\n",
    "#         print(f\"‚ö†Ô∏è No data found for song with index {song_index}.\")\n",
    "#         return\n",
    "\n",
    "#     if clusters_to_plot is not None:\n",
    "#         if isinstance(clusters_to_plot, int):\n",
    "#             clusters_to_plot = [clusters_to_plot]\n",
    "#         label_col = 'Second Labels' if 'Second Labels' in clustered_segments.columns else 'Label'\n",
    "#         clustered_segments = clustered_segments[clustered_segments[label_col].isin(clusters_to_plot)]\n",
    "\n",
    "#     full_frequency = song_data[\"Frequency\"].values\n",
    "#     full_time = np.arange(len(full_frequency))\n",
    "#     tonic_note = song_data[\"Tonic\"].iloc[0]\n",
    "#     song_name = song_data[\"SongName\"].iloc[0]\n",
    "\n",
    "#     label_col = 'Second Labels' if 'Second Labels' in clustered_segments.columns else 'Label'\n",
    "#     unique_labels = sorted(clustered_segments[label_col].unique())\n",
    "#     cmap = plt.get_cmap('tab20', len(unique_labels))\n",
    "#     label_to_color = {label: cmap(i) for i, label in enumerate(unique_labels)}\n",
    "\n",
    "#     plt.style.use('dark_background')\n",
    "#     plt.figure(figsize=(18, 8))\n",
    "\n",
    "#     plt.plot(full_time, full_frequency, color='gray', alpha=0.5)\n",
    "\n",
    "#     for _, row in clustered_segments.iterrows():\n",
    "#         start = int(row['StartFrame'])\n",
    "#         end = int(row['EndFrame'])\n",
    "#         label = row[label_col]\n",
    "#         color = label_to_color.get(label, 'black')\n",
    "        \n",
    "#         plt.plot(full_time[start:end], full_frequency[start:end],\n",
    "#                  color=color, linewidth=2)\n",
    "\n",
    "#     carnatic_frequencies = {note: librosa.note_to_hz(tonic_note) * ratio for note, ratio in CARNATIC_RATIOS.items()}\n",
    "#     valid_freqs = song_data['Frequency'].dropna()\n",
    "#     if not valid_freqs.empty:\n",
    "#         min_freq = valid_freqs.min()\n",
    "#         max_freq = valid_freqs.max()\n",
    "#         for note, freq in carnatic_frequencies.items():\n",
    "#             if min_freq <= freq <= max_freq:\n",
    "#                 plt.axhline(y=freq, color='orange', linestyle='--', linewidth=0.8)\n",
    "#                 plt.text(len(full_frequency) * 1.005, freq, note, color='orange', fontsize=9, verticalalignment='center')\n",
    "    \n",
    "#     # --- LEGEND CODE REMOVED ---\n",
    "\n",
    "#     plt.title(f\"Clustered F0 Contour for Song: '{song_name}' (Tonic: {tonic_note})\")\n",
    "#     plt.xlabel(\"Time (frames)\")\n",
    "#     plt.ylabel(\"Frequency (Hz)\")\n",
    "#     plt.ylim(valid_freqs.min() - 10, valid_freqs.max() + 10)\n",
    "#     plt.grid(alpha=0.3)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "# def play_and_plot_cluster(audio_dir: str, cluster_number: int, song_index: int, sr: int = 44100):\n",
    "#     \"\"\"\n",
    "#     Plots segments of a cluster from a specific song in context, then shows a second \n",
    "#     plot with only those segments overlaid for similarity, and plays their audio.\n",
    "#     \"\"\"\n",
    "#     raaga_name = Path(audio_dir).name\n",
    "#     if raaga_name.endswith('_Vocals'):\n",
    "#         raaga_name = raaga_name.replace('_Vocals', '')\n",
    "\n",
    "#     paths = get_data_paths(raaga_name)\n",
    "    \n",
    "#     try:\n",
    "#         master_df = pd.read_csv(paths[\"master_csv\"])\n",
    "#         carva_df = pd.read_csv(paths[\"carva_csv\"])\n",
    "#     except FileNotFoundError as e:\n",
    "#         print(f\"‚ùå Required data file not found: {e}\")\n",
    "#         return\n",
    "\n",
    "#     label_col = 'Second Labels' if 'Second Labels' in carva_df.columns else 'Label'\n",
    "    \n",
    "#     # Filter for segments from the specific cluster AND song\n",
    "#     cluster_in_song_segments = carva_df[\n",
    "#         (carva_df[label_col] == cluster_number) &\n",
    "#         (carva_df['Index'] == song_index)\n",
    "#     ]\n",
    "    \n",
    "#     if cluster_in_song_segments.empty:\n",
    "#         print(f\"‚ö†Ô∏è No segments found for cluster {cluster_number} in song index {song_index}.\")\n",
    "#         return\n",
    "\n",
    "#     song_data = master_df[master_df[\"Index\"] == song_index].reset_index(drop=True)\n",
    "#     if song_data.empty:\n",
    "#         print(f\"‚ö†Ô∏è No data found for song index {song_index} in the master CSV.\")\n",
    "#         return\n",
    "\n",
    "#     print(f\"üîç Analyzing Cluster {cluster_number} in Song Index {song_index}...\")\n",
    "\n",
    "#     # PLOT 1: Segments in their original song context\n",
    "#     plt.style.use('dark_background')\n",
    "#     plt.figure(figsize=(18, 8))\n",
    "#     ax1 = plt.gca()\n",
    "\n",
    "#     full_frequency = song_data[\"Frequency\"].values\n",
    "#     full_time = np.arange(len(full_frequency))\n",
    "#     tonic_note = song_data[\"Tonic\"].iloc[0]\n",
    "#     song_name = song_data[\"SongName\"].iloc[0]\n",
    "\n",
    "#     ax1.plot(full_time, full_frequency, color='gray', alpha=0.5, label='F0 Contour')\n",
    "    \n",
    "#     random.seed(cluster_number)\n",
    "#     cluster_color = '#%06x' % random.randint(0, 0xFFFFFF)\n",
    "    \n",
    "#     for i, (_, row) in enumerate(cluster_in_song_segments.iterrows()):\n",
    "#         start_frame = int(row['StartFrame'])\n",
    "#         end_frame = int(row['EndFrame'])\n",
    "#         ax1.plot(full_time[start_frame:end_frame], \n",
    "#                  full_frequency[start_frame:end_frame], \n",
    "#                  color=cluster_color, linewidth=2, \n",
    "#                  label=f\"Cluster {cluster_number}\" if i == 0 else \"\")\n",
    "            \n",
    "#     carnatic_frequencies = {note: librosa.note_to_hz(tonic_note) * ratio for note, ratio in CARNATIC_RATIOS.items()}\n",
    "#     valid_freqs = song_data['Frequency'].dropna()\n",
    "#     if not valid_freqs.empty:\n",
    "#         min_freq, max_freq = valid_freqs.min(), valid_freqs.max()\n",
    "#         for note, freq in carnatic_frequencies.items():\n",
    "#             if min_freq <= freq <= max_freq:\n",
    "#                 ax1.axhline(y=freq, color='orange', linestyle='--', linewidth=0.8)\n",
    "#                 ax1.text(ax1.get_xlim()[1] * 1.005, freq, note, color='orange', fontsize=9, verticalalignment='center')\n",
    "    \n",
    "#     ax1.set_title(f\"Context Plot for Cluster {cluster_number} in Song: '{song_name}'\")\n",
    "#     ax1.set_xlabel(\"Time (frames)\")\n",
    "#     ax1.set_ylabel(\"Frequency (Hz)\")\n",
    "#     ax1.legend(loc='upper right')\n",
    "#     ax1.grid(alpha=0.3)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     # --- MODIFIED PLOT 2 ---\n",
    "#     # PLOT 2: Segments from THIS SONG ONLY overlaid for similarity\n",
    "#     print(f\"\\nüìà Plotting the {len(cluster_in_song_segments)} segments from Cluster {cluster_number} in this song, overlaid for comparison...\")\n",
    "    \n",
    "#     plt.style.use('dark_background')\n",
    "#     plt.figure(figsize=(12, 7))\n",
    "#     ax2 = plt.gca()\n",
    "    \n",
    "#     all_freqs_in_cluster = []\n",
    "\n",
    "#     # Iterate over the segments from THIS SONG ONLY\n",
    "#     for _, row in cluster_in_song_segments.iterrows():\n",
    "#         seg_start = int(row['StartFrame'])\n",
    "#         seg_end = int(row['EndFrame'])\n",
    "        \n",
    "#         # We can use the 'song_data' dataframe directly since we already filtered for this song\n",
    "#         segment_freq_data = song_data['Frequency'].values[seg_start:seg_end]\n",
    "        \n",
    "#         if len(segment_freq_data) > 0:\n",
    "#             ax2.plot(np.arange(len(segment_freq_data)), segment_freq_data, color='cyan', alpha=0.4, linewidth=1.5)\n",
    "#             all_freqs_in_cluster.extend(segment_freq_data)\n",
    "            \n",
    "#     if all_freqs_in_cluster:\n",
    "#         valid_cluster_freqs = [f for f in all_freqs_in_cluster if pd.notna(f)]\n",
    "#         if valid_cluster_freqs:\n",
    "#             min_freq_cluster, max_freq_cluster = min(valid_cluster_freqs), max(valid_cluster_freqs)\n",
    "#             for note, freq in carnatic_frequencies.items():\n",
    "#                 if min_freq_cluster <= freq <= max_freq_cluster:\n",
    "#                     ax2.axhline(y=freq, color='orange', linestyle='--', linewidth=0.8)\n",
    "#                     ax2.text(ax2.get_xlim()[1] * 1.005, freq, note, color='orange', fontsize=9, verticalalignment='center')\n",
    "#             ax2.set_ylim(min_freq_cluster - 10, max_freq_cluster + 10)\n",
    "\n",
    "#     ax2.set_title(f\"Shape Comparison of Segments in Cluster {cluster_number} from Song '{song_name}'\")\n",
    "#     ax2.set_xlabel(\"Time (frames within segment)\")\n",
    "#     ax2.set_ylabel(\"Frequency (Hz)\")\n",
    "#     ax2.grid(alpha=0.3)\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "\n",
    "#     # AUDIO PLAYBACK (unchanged)\n",
    "#     print(\"\\nüéß Playing segments from the specified song:\")\n",
    "#     for _, row in cluster_in_song_segments.iterrows():\n",
    "#         start_frame = int(row['StartFrame'])\n",
    "#         end_frame = int(row['EndFrame'])\n",
    "#         audio_path = row['AudioPath']\n",
    "        \n",
    "#         print(f\"   - Frames: {start_frame}-{end_frame}\")\n",
    "#         song_time_data = song_data['Time'].reset_index(drop=True)\n",
    "#         start_time = song_time_data.get(start_frame, 0)\n",
    "#         end_time = song_time_data.get(end_frame, song_time_data.iloc[-1])\n",
    "        \n",
    "#         try:\n",
    "#             audio, _ = librosa.load(audio_path, sr=sr)\n",
    "#             start_sample = int(start_time * sr)\n",
    "#             end_sample = int(end_time * sr)\n",
    "#             if end_sample > start_sample:\n",
    "#                 ipd.display(ipd.Audio(audio[start_sample:end_sample], rate=sr))\n",
    "#             else:\n",
    "#                 print(\"   ‚ö†Ô∏è Invalid segment length, skipping playback.\")\n",
    "#         except Exception as e:\n",
    "#             print(f\"   ‚ö†Ô∏è Could not load or play audio from {audio_path}: {e}\")\n",
    "\n",
    "#     print(\"---------------------------------\")\n",
    "\n",
    "# def evaluate_clustering_results(audio_dir: str, song_idx: int, carva_path: str):\n",
    "#     \"\"\"\n",
    "#     Evaluates and visualizes clustering results for a specific song.\n",
    "#     \"\"\"\n",
    "#     raaga_name = Path(audio_dir).name\n",
    "#     if raaga_name.endswith('_Vocals'):\n",
    "#         raaga_name = raaga_name.replace('_Vocals', '')\n",
    "        \n",
    "#     paths = get_data_paths(raaga_name)\n",
    "    \n",
    "#     try:\n",
    "#         master_df = pd.read_csv(paths[\"master_csv\"])\n",
    "#         carva_df = pd.read_csv(carva_path)\n",
    "#     except FileNotFoundError as e:\n",
    "#         print(f\"‚ùå Required data file not found: {e}.\")\n",
    "#         return\n",
    "\n",
    "#     # Filter data for the specific song\n",
    "#     song_master_df = master_df[master_df[\"Index\"] == song_idx]\n",
    "    \n",
    "#     if song_master_df.empty:\n",
    "#         print(f\"‚ö†Ô∏è No data found for song index {song_idx} in the master file.\")\n",
    "#         return\n",
    "        \n",
    "#     song_name = song_master_df[\"SongName\"].iloc[0]\n",
    "\n",
    "#     print(f\"üìä Evaluating clustering for song: '{song_name}' (Index: {song_idx})\")\n",
    "\n",
    "#     # 1. Percentage of song clustered (Corrected for overlap)\n",
    "#     total_song_frames = len(song_master_df)\n",
    "    \n",
    "#     song_carva_df = carva_df[carva_df['Index'] == song_idx]\n",
    "\n",
    "#     if song_carva_df.empty:\n",
    "#         total_clustered_frames = 0\n",
    "#     else:\n",
    "#         is_clustered = np.zeros(total_song_frames, dtype=bool)\n",
    "#         for _, row in song_carva_df.iterrows():\n",
    "#             start = int(row['StartFrame'])\n",
    "#             end = int(row['EndFrame'])\n",
    "#             if end > start and end <= total_song_frames: # Added boundary check\n",
    "#                 is_clustered[start:end] = True\n",
    "        \n",
    "#         total_clustered_frames = np.sum(is_clustered)\n",
    "\n",
    "#     percentage_clustered = (total_clustered_frames / total_song_frames) * 100 if total_song_frames > 0 else 0\n",
    "#     print(f\"   ‚Ä¢ Percentage of song clustered: {percentage_clustered:.2f}%\")\n",
    "\n",
    "#     # 2. Total number of clusters\n",
    "#     if song_carva_df.empty:\n",
    "#         num_clusters = 0\n",
    "#     else:\n",
    "#         num_clusters = song_carva_df['Label'].nunique()\n",
    "#     print(f\"   ‚Ä¢ Total number of clusters found: {num_clusters}\")\n",
    "\n",
    "#     # 3. Plotting the metrics\n",
    "#     if not song_carva_df.empty:\n",
    "#         song_carva_df['SegmentLength'] = song_carva_df['EndFrame'] - song_carva_df['StartFrame']\n",
    "        \n",
    "#         # Plot 1: Histogram of segment lengths\n",
    "#         plt.style.use('dark_background')\n",
    "#         plt.figure(figsize=(10, 6))\n",
    "#         cluster_lengths = song_carva_df.groupby('Label')['SegmentLength'].first()\n",
    "#         if not cluster_lengths.empty:\n",
    "#             plt.hist(cluster_lengths, bins=range(cluster_lengths.min(), cluster_lengths.max() + 2), edgecolor='white')\n",
    "#             plt.title(f\"Distribution of Cluster Segment Lengths for '{song_name}'\")\n",
    "#             plt.xlabel(\"Segment Length (frames)\")\n",
    "#             plt.ylabel(\"Number of Clusters\")\n",
    "#             plt.grid(alpha=0.3)\n",
    "#             plt.show()\n",
    "\n",
    "#         # --- MODIFIED PLOT ---\n",
    "#         # Plot 2: Bar chart showing the number of elements in each cluster\n",
    "#         plt.style.use('dark_background')\n",
    "#         plt.figure(figsize=(12, 8))\n",
    "        \n",
    "#         cluster_sizes = song_carva_df.groupby('Label')['Index'].count().sort_values(ascending=False)\n",
    "        \n",
    "#         cluster_sizes.plot(kind='bar', edgecolor='white', alpha=0.8, color='cyan')\n",
    "        \n",
    "#         plt.title(f\"Number of Segments per Cluster for '{song_name}'\")\n",
    "#         plt.xlabel(\"Cluster Label\")\n",
    "#         plt.ylabel(\"Number of Segments\")\n",
    "#         plt.xticks(rotation=45, ha='right')\n",
    "#         plt.grid(axis='y', alpha=0.3)\n",
    "#         plt.tight_layout() # Adjust layout to prevent labels from overlapping\n",
    "#         plt.show()\n",
    "#     else:\n",
    "#         print(\"   ‚Ä¢ No clustered segments to plot.\")\n",
    "\n",
    "# def clean_np_float_list(seg_str: str) -> np.ndarray:\n",
    "#     \"\"\"Convert a stringified list with np.float64 entries into a proper list of floats.\"\"\"\n",
    "#     cleaned = re.sub(r'np\\\\.float64\\\\(([^)]+)\\\\)', r'\\\\1', seg_str)\n",
    "#     return np.array(ast.literal_eval(cleaned), dtype=float)\n",
    "# def interpolate_list(lst, target_len: int) -> list:\n",
    "#     \"\"\"\n",
    "#     Corrected version: Interpolates a list or NumPy array to a target length,\n",
    "#     and correctly handles empty inputs.\n",
    "#     \"\"\"\n",
    "#     # --- FIX: Explicitly check the length of the list/array ---\n",
    "#     if lst is None or len(lst) == 0:\n",
    "#         return [0.0] * target_len\n",
    "#     # -----------------------------------------------------------\n",
    "    \n",
    "#     original_len = len(lst)\n",
    "#     return list(np.interp(np.linspace(0, original_len - 1, target_len),\n",
    "#                           np.arange(original_len), lst))\n",
    "# def recluster_with_dtw(audio_dir: str, config: Dict, song_index: Optional[int] = None):\n",
    "#     \"\"\"\n",
    "#     Takes segments from the carva file, interpolates them to a fixed length,\n",
    "#     and then re-clusters them using an all-vs-all DTW comparison.\n",
    "#     \"\"\"\n",
    "#     raaga_name = Path(audio_dir).name\n",
    "#     if raaga_name.endswith('_Vocals'):\n",
    "#         raaga_name = raaga_name.replace('_Vocals', '')\n",
    "        \n",
    "#     paths = get_data_paths(raaga_name)\n",
    "#     carva_path = paths[\"carva_csv\"]\n",
    "\n",
    "#     print(f\"üî¨ Starting DTW re-clustering for '{raaga_name}'...\")\n",
    "    \n",
    "#     try:\n",
    "#         carva_df = pd.read_csv(carva_path)\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"‚ùå ERROR: File not found at {carva_path}\")\n",
    "#         return\n",
    "\n",
    "#     # 1. Load Data & Filter\n",
    "#     if song_index is not None:\n",
    "#         print(f\" targeting song with Index: {song_index}\")\n",
    "#         target_df = carva_df[carva_df['Index'] == song_index].copy()\n",
    "#     else:\n",
    "#         print(\" targeting all songs.\")\n",
    "#         target_df = carva_df.copy()\n",
    "        \n",
    "#     # --- DEBUG ---\n",
    "#     print(f\"DEBUG: Found {len(carva_df)} total rows in the carva file.\")\n",
    "#     if song_index is not None:\n",
    "#         print(f\"DEBUG: Found {len(target_df)} segments belonging to song index {song_index}.\")\n",
    "#     # -------------\n",
    "\n",
    "#     if target_df.empty:\n",
    "#         print(\"‚ö†Ô∏è No segments found for the specified criteria.\")\n",
    "#         return\n",
    "        \n",
    "#     interpolation_size = config.get(\"interpolation_size\", 50)\n",
    "#     similarity_threshold = config.get(\"dtw_similarity_threshold\", 1.5)\n",
    "\n",
    "#     # 2. Prepare Segments: Parse and Interpolate\n",
    "#     interpolated_segments = []\n",
    "#     valid_original_indices = target_df.index.tolist() \n",
    "    \n",
    "#     print(\"DEBUG: Starting to parse and interpolate segments...\")\n",
    "#     for i, seg_str in target_df['SegmentList'].items(): # Use .items() to get original index i\n",
    "#         try:\n",
    "#             segment = clean_np_float_list(seg_str)\n",
    "#             if len(segment) > 0:\n",
    "#                 interpolated = interpolate_list(segment, interpolation_size)\n",
    "#                 interpolated_segments.append(np.array(interpolated))\n",
    "#                 # --- DEBUG ---\n",
    "#                 print(f\"  Row {i}: ‚úÖ Successfully interpolated segment.\")\n",
    "#                 # -------------\n",
    "#             else:\n",
    "#                 interpolated_segments.append(None)\n",
    "#         except (ValueError, SyntaxError) as e:\n",
    "#             interpolated_segments.append(None)\n",
    "#             # --- DEBUG ---\n",
    "#             print(f\"  Row {i}: ‚ùå FAILED to parse segment. Error: {e}\")\n",
    "#             # -------------\n",
    "    \n",
    "#     final_segments = [seg for seg in interpolated_segments if seg is not None]\n",
    "#     final_indices = [idx for i, idx in enumerate(valid_original_indices) if interpolated_segments[i] is not None]\n",
    "\n",
    "#     print(f\"Found {len(final_segments)} valid segments to re-cluster.\")\n",
    "\n",
    "#     if len(final_segments) < 2:\n",
    "#         print(\"‚ö†Ô∏è Not enough valid segments (< 2) to perform DTW clustering.\")\n",
    "#         return\n",
    "\n",
    "#     # 3. DTW Distance Matrix Calculation\n",
    "#     num_segments = len(final_segments)\n",
    "#     dist_matrix = np.zeros((num_segments, num_segments))\n",
    "    \n",
    "#     # --- DEBUG ---\n",
    "#     print(f\"DEBUG: Starting DTW comparison for {num_segments} segments.\")\n",
    "#     # -------------\n",
    "\n",
    "#     for i in tqdm(range(num_segments), desc=\"Calculating DTW Matrix\"):\n",
    "#         for j in range(i + 1, num_segments):\n",
    "#             dist, _ = fastdtw(final_segments[i], final_segments[j])\n",
    "#             dist_matrix[i, j] = dist\n",
    "#             dist_matrix[j, i] = dist\n",
    "            \n",
    "#     # (The rest of the function continues as before)\n",
    "#     print(\"üß¨ Performing hierarchical clustering...\")\n",
    "#     clustering = AgglomerativeClustering(\n",
    "#         n_clusters=None,\n",
    "#         distance_threshold=similarity_threshold,\n",
    "#         metric='precomputed',\n",
    "#         linkage='average'\n",
    "#     )\n",
    "#     labels = clustering.fit_predict(dist_matrix)\n",
    "\n",
    "#     if 'DTW_Label' not in carva_df.columns:\n",
    "#         carva_df['DTW_Label'] = -1\n",
    "    \n",
    "#     carva_df.loc[final_indices, 'DTW_Label'] = labels\n",
    "#     carva_df.to_csv(carva_path, index=False)\n",
    "    \n",
    "#     print(f\"\\n‚úÖ DTW re-clustering finished! Found {len(set(labels))} new clusters.\")\n",
    "#     print(f\"üíæ Updated {carva_path} with 'DTW_Label' column.\")\n",
    "# def recluster_with_pca(audio_dir: str, config: Dict, song_index: Optional[int] = None):\n",
    "#     \"\"\"\n",
    "#     Takes segments from the carva file, interpolates them, and re-clusters them\n",
    "#     using the fast PCA method instead of DTW.\n",
    "#     \"\"\"\n",
    "#     raaga_name = Path(audio_dir).name\n",
    "#     if raaga_name.endswith('_Vocals'):\n",
    "#         raaga_name = raaga_name.replace('_Vocals', '')\n",
    "        \n",
    "#     paths = get_data_paths(raaga_name)\n",
    "#     carva_path = paths[\"carva_csv\"]\n",
    "\n",
    "#     print(f\"üî¨ Starting PCA re-clustering for '{raaga_name}'...\")\n",
    "    \n",
    "#     try:\n",
    "#         carva_df = pd.read_csv(carva_path)\n",
    "#     except FileNotFoundError:\n",
    "#         print(f\"‚ùå ERROR: File not found at {carva_path}\")\n",
    "#         return\n",
    "\n",
    "#     # 1. Load Data & Filter\n",
    "#     if song_index is not None:\n",
    "#         print(f\" targeting song with Index: {song_index}\")\n",
    "#         target_df = carva_df[carva_df['Index'] == song_index].copy()\n",
    "#     else:\n",
    "#         print(\" targeting all songs.\")\n",
    "#         target_df = carva_df.copy()\n",
    "\n",
    "#     if target_df.empty:\n",
    "#         print(\"‚ö†Ô∏è No segments found for the specified criteria.\")\n",
    "#         return\n",
    "        \n",
    "#     interpolation_size = config.get(\"interpolation_size\", 50)\n",
    "#     similarity_threshold = config.get(\"pca_similarity_threshold\", 0.7)\n",
    "#     pca_components = config.get(\"pca_components\", 10)\n",
    "\n",
    "#     # 2. Prepare Segments: Parse and Interpolate\n",
    "#     interpolated_segments = []\n",
    "#     valid_original_indices = target_df.index.tolist() \n",
    "    \n",
    "#     for seg_str in target_df['SegmentList']:\n",
    "#         try:\n",
    "#             segment = clean_np_float_list(seg_str)\n",
    "#             if len(segment) > 0:\n",
    "#                 interpolated = interpolate_list(segment, interpolation_size)\n",
    "#                 interpolated_segments.append(np.array(interpolated))\n",
    "#             else:\n",
    "#                 interpolated_segments.append(None)\n",
    "#         except (ValueError, SyntaxError):\n",
    "#             interpolated_segments.append(None)\n",
    "    \n",
    "#     final_segments = [seg for seg in interpolated_segments if seg is not None]\n",
    "#     final_indices = [idx for i, idx in enumerate(valid_original_indices) if interpolated_segments[i] is not None]\n",
    "\n",
    "#     print(f\"Found {len(final_segments)} valid segments to re-cluster.\")\n",
    "\n",
    "#     if len(final_segments) < 2:\n",
    "#         print(\"‚ö†Ô∏è Not enough valid segments (< 2) to perform PCA clustering.\")\n",
    "#         return\n",
    "\n",
    "#     # 3. Perform PCA and Calculate Distance Matrix\n",
    "#     print(\"ü§ñ Performing PCA transformation...\")\n",
    "#     X_abs = np.stack(final_segments)\n",
    "#     X_shape = X_abs - np.mean(X_abs, axis=1, keepdims=True)\n",
    "#     X_combined = np.concatenate([X_abs, X_shape], axis=1)\n",
    "\n",
    "#     pca = PCA(n_components=min(pca_components, X_combined.shape[1]))\n",
    "#     X_pca = pca.fit_transform(X_combined)\n",
    "#     dist_matrix = squareform(pdist(X_pca, metric='euclidean'))\n",
    "            \n",
    "#     # 4. Perform Clustering\n",
    "#     print(\"üß¨ Performing hierarchical clustering...\")\n",
    "#     clustering = AgglomerativeClustering(\n",
    "#         n_clusters=None,\n",
    "#         distance_threshold=similarity_threshold,\n",
    "#         metric='precomputed',\n",
    "#         linkage='average'\n",
    "#     )\n",
    "#     labels = clustering.fit_predict(dist_matrix)\n",
    "\n",
    "#     # 5. Update the carva.csv file\n",
    "#     if 'PCA_Label' not in carva_df.columns:\n",
    "#         carva_df['PCA_Label'] = -1\n",
    "    \n",
    "#     carva_df.loc[final_indices, 'PCA_Label'] = labels\n",
    "#     carva_df.to_csv(carva_path, index=False)\n",
    "    \n",
    "#     print(f\"\\n‚úÖ PCA re-clustering finished! Found {len(set(labels))} new clusters.\")\n",
    "#     print(f\"üíæ Updated {carva_path} with 'PCA_Label' column.\")\n",
    "\n",
    "# def play_and_plot_secondary_cluster(audio_dir: str, cluster_number: int, song_index: int, sr: int = 44100):\n",
    "#     \"\"\"\n",
    "#     Plots segments of a SECONDARY cluster from a specific song in context, shows a \n",
    "#     second plot with only those segments overlaid, and plays their audio.\n",
    "#     \"\"\"\n",
    "#     raaga_name = Path(audio_dir).name\n",
    "#     if raaga_name.endswith('_Vocals'):\n",
    "#         raaga_name = raaga_name.replace('_Vocals', '')\n",
    "\n",
    "#     paths = get_data_paths(raaga_name)\n",
    "    \n",
    "#     try:\n",
    "#         master_df = pd.read_csv(paths[\"master_csv\"])\n",
    "#         carva_df = pd.read_csv(paths[\"carva_csv\"])\n",
    "#     except FileNotFoundError as e:\n",
    "#         print(f\"‚ùå Required data file not found: {e}\")\n",
    "#         return\n",
    "\n",
    "#     # --- KEY CHANGE: Automatically find the secondary label column ---\n",
    "#     if 'DTW_Label' in carva_df.columns:\n",
    "#         label_col = 'DTW_Label'\n",
    "#     elif 'PCA_Label' in carva_df.columns:\n",
    "#         label_col = 'PCA_Label'\n",
    "#     elif 'Second Labels' in carva_df.columns:\n",
    "#         label_col = 'Second Labels'\n",
    "#     else:\n",
    "#         print(\"‚ùå Error: No secondary label column ('DTW_Label', 'PCA_Label', or 'Second Labels') found in carva.csv.\")\n",
    "#         return\n",
    "    \n",
    "#     print(f\"INFO: Using secondary cluster column: '{label_col}'\")\n",
    "#     # -----------------------------------------------------------------\n",
    "    \n",
    "#     # Filter for segments from the specific secondary cluster AND song\n",
    "#     cluster_in_song_segments = carva_df[\n",
    "#         (carva_df[label_col] == cluster_number) &\n",
    "#         (carva_df['Index'] == song_index)\n",
    "#     ]\n",
    "    \n",
    "#     if cluster_in_song_segments.empty:\n",
    "#         print(f\"‚ö†Ô∏è No segments found for secondary cluster {cluster_number} in song index {song_index}.\")\n",
    "#         return\n",
    "\n",
    "#     song_data = master_df[master_df[\"Index\"] == song_index].reset_index(drop=True)\n",
    "#     if song_data.empty:\n",
    "#         print(f\"‚ö†Ô∏è No data found for song index {song_index} in the master CSV.\")\n",
    "#         return\n",
    "\n",
    "#     print(f\"üîç Analyzing Secondary Cluster {cluster_number} in Song Index {song_index}...\")\n",
    "\n",
    "#     # (The rest of the plotting and playback logic is the same)\n",
    "\n",
    "#     # PLOT 1: Segments in their original song context\n",
    "#     plt.style.use('dark_background')\n",
    "#     plt.figure(figsize=(18, 8))\n",
    "#     ax1 = plt.gca()\n",
    "#     full_frequency = song_data[\"Frequency\"].values\n",
    "#     x_axis_time = song_data[\"Time\"].values # Using real time for x-axis\n",
    "#     tonic_note = song_data[\"Tonic\"].iloc[0]\n",
    "#     song_name = song_data[\"SongName\"].iloc[0]\n",
    "#     ax1.plot(x_axis_time, full_frequency, color='gray', alpha=0.5, label='F0 Contour')\n",
    "#     random.seed(cluster_number)\n",
    "#     cluster_color = '#%06x' % random.randint(0, 0xFFFFFF)\n",
    "#     for i, (_, row) in enumerate(cluster_in_song_segments.iterrows()):\n",
    "#         start_frame, end_frame = int(row['StartFrame']), int(row['EndFrame'])\n",
    "#         ax1.plot(x_axis_time[start_frame:end_frame], full_frequency[start_frame:end_frame], \n",
    "#                  color=cluster_color, linewidth=2, label=f\"Cluster {cluster_number}\" if i == 0 else \"\")\n",
    "#     carnatic_frequencies = {note: librosa.note_to_hz(tonic_note) * ratio for note, ratio in CARNATIC_RATIOS.items()}\n",
    "#     valid_freqs = song_data['Frequency'].dropna()\n",
    "#     if not valid_freqs.empty:\n",
    "#         min_freq, max_freq = valid_freqs.min(), valid_freqs.max()\n",
    "#         plot_end_time = ax1.get_xlim()[1]\n",
    "#         for note, freq in carnatic_frequencies.items():\n",
    "#             if min_freq <= freq <= max_freq:\n",
    "#                 ax1.axhline(y=freq, color='orange', linestyle='--', linewidth=0.8)\n",
    "#                 ax1.text(plot_end_time * 1.005, freq, note, color='orange', fontsize=9, verticalalignment='center')\n",
    "#     ax1.set_title(f\"Context Plot for Secondary Cluster {cluster_number} in Song: '{song_name}'\")\n",
    "#     ax1.set_xlabel(\"Time (seconds)\"), ax1.set_ylabel(\"Frequency (Hz)\"), ax1.legend(loc='upper right'), ax1.grid(alpha=0.3)\n",
    "#     plt.tight_layout(), plt.show()\n",
    "\n",
    "#     # PLOT 2: Segments from THIS SONG ONLY overlaid for similarity\n",
    "#     print(f\"\\nüìà Plotting the {len(cluster_in_song_segments)} segments from Secondary Cluster {cluster_number} in this song, overlaid for comparison...\")\n",
    "#     plt.style.use('dark_background'), plt.figure(figsize=(12, 7)), (ax2 := plt.gca())\n",
    "#     all_freqs_in_cluster = []\n",
    "#     for _, row in cluster_in_song_segments.iterrows():\n",
    "#         start_frame, end_frame = int(row['StartFrame']), int(row['EndFrame'])\n",
    "#         segment_freq_data = song_data['Frequency'].values[start_frame:end_frame]\n",
    "#         if len(segment_freq_data) > 0:\n",
    "#             ax2.plot(np.arange(len(segment_freq_data)), segment_freq_data, color='cyan', alpha=0.4, linewidth=1.5)\n",
    "#             all_freqs_in_cluster.extend(segment_freq_data)\n",
    "#     if all_freqs_in_cluster:\n",
    "#         valid_cluster_freqs = [f for f in all_freqs_in_cluster if pd.notna(f)]\n",
    "#         if valid_cluster_freqs:\n",
    "#             min_freq_cluster, max_freq_cluster = min(valid_cluster_freqs), max(valid_cluster_freqs)\n",
    "#             for note, freq in carnatic_frequencies.items():\n",
    "#                 if min_freq_cluster <= freq <= max_freq_cluster:\n",
    "#                     ax2.axhline(y=freq, color='orange', linestyle='--', linewidth=0.8)\n",
    "#                     ax2.text(ax2.get_xlim()[1] * 1.005, freq, note, color='orange', fontsize=9, verticalalignment='center')\n",
    "#             ax2.set_ylim(min_freq_cluster - 10, max_freq_cluster + 10)\n",
    "#     ax2.set_title(f\"Shape Comparison of Segments in Secondary Cluster {cluster_number} from Song '{song_name}'\")\n",
    "#     ax2.set_xlabel(\"Time (frames within segment)\"), ax2.set_ylabel(\"Frequency (Hz)\"), ax2.grid(alpha=0.3)\n",
    "#     plt.tight_layout(), plt.show()\n",
    "\n",
    "#     # AUDIO PLAYBACK\n",
    "#     print(\"\\nüéß Playing segments from the specified song:\")\n",
    "#     song_time_data = song_data['Time'].values\n",
    "#     audio_path = cluster_in_song_segments['AudioPath'].iloc[0]\n",
    "#     try:\n",
    "#         audio, native_sr = librosa.load(audio_path, sr=None)\n",
    "#         if sr and native_sr != sr:\n",
    "#             audio = librosa.resample(y=audio, orig_sr=native_sr, target_sr=sr)\n",
    "#     except Exception as e:\n",
    "#         print(f\"‚ö†Ô∏è Could not load audio from {audio_path}: {e}\")\n",
    "#         return\n",
    "#     for _, row in cluster_in_song_segments.iterrows():\n",
    "#         start_frame, end_frame = int(row['StartFrame']), int(row['EndFrame'])\n",
    "#         if start_frame >= len(song_time_data) or end_frame > len(song_time_data):\n",
    "#             print(f\"   - Frames: {start_frame}-{end_frame}: ‚ö†Ô∏è Invalid frame indices, skipping.\")\n",
    "#             continue\n",
    "#         start_time, end_time = song_time_data[start_frame], song_time_data[end_frame - 1]\n",
    "#         print(f\"   - Frames: {start_frame}-{end_frame} -> Playing from {start_time:.2f}s to {end_time:.2f}s\")\n",
    "#         start_sample, end_sample = int(start_time * sr), int(end_time * sr)\n",
    "#         if end_sample > start_sample:\n",
    "#             ipd.display(ipd.Audio(audio[start_sample:end_sample], rate=sr))\n",
    "#         else:\n",
    "#             print(\"   ‚ö†Ô∏è Calculated segment duration is zero, skipping.\")\n",
    "#     print(\"---------------------------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b14a155",
   "metadata": {},
   "source": [
    "Cell 4: Round 1 Evalutation & Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b82127",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_idx=5\n",
    "evaluate_clustering_results(audio_dir, song_idx)  # Example usage with first song\n",
    "cluster_curve(audio_dir, song_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72309553",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_and_plot_cluster(audio_dir, 13, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b77fa2c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "recluster_with_pca(audio_dir, CONFIG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c934bf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "play_and_plot_secondary_cluster(audio_dir, 26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b98e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# (This function can be placed in your carnatic_functions.py file)\n",
    "LABELING_CONFIG = {\n",
    "    \"histogram_bins\": 100,      # How many bins to use for frequency analysis\n",
    "    \"peak_prominence\": 0.15,    # How prominent a histogram peak must be to be considered a note\n",
    "    \"max_notes_in_label\": 3     # The maximum number of notes to include in the final label\n",
    "}\n",
    "\n",
    "def auto_label_cluster(audio_dir: str, cluster_number: int, config: Dict = LABELING_CONFIG):\n",
    "\n",
    "    raaga_name = Path(audio_dir).name.replace('_Vocals', '')\n",
    "    paths = get_data_paths(raaga_name)\n",
    "    \n",
    "    try:\n",
    "        master_df = pd.read_csv(paths[\"master_csv\"])\n",
    "        carva_df = pd.read_csv(paths[\"carva_csv\"])\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"‚ùå Required data file not found: {e}\"); return\n",
    "\n",
    "    label_col = next((col for col in ['DTW_Label', 'PCA_Label', 'Second Labels', 'Label'] if col in carva_df.columns), None)\n",
    "    if not label_col:\n",
    "        print(\"‚ùå No label column found in carva.csv.\"); return\n",
    "\n",
    "    cluster_rows = carva_df[carva_df[label_col] == cluster_number]\n",
    "    if cluster_rows.empty:\n",
    "        print(f\"‚ö†Ô∏è No segments found for cluster {cluster_number}.\"); return\n",
    "\n",
    "    # Determine a representative tonic for the cluster to get the swara map\n",
    "    tonic = master_df[master_df['Index'] == cluster_rows.iloc[0]['Index']]['Tonic'].iloc[0]\n",
    "    carnatic_frequencies = {note: librosa.note_to_hz(tonic) * ratio for note, ratio in CARNATIC_RATIOS.items()}\n",
    "\n",
    "    # This list will store the simplified note sequence for each segment\n",
    "    list_of_sequences = []\n",
    "\n",
    "    for _, row in cluster_rows.iterrows():\n",
    "        try:\n",
    "            segment_data = clean_np_float_list(row['SegmentList'])\n",
    "            if len(segment_data) < 5: continue\n",
    "\n",
    "            # --- NEW SEQUENCE LOGIC ---\n",
    "            # 1. Convert every frequency point in the segment to its closest swara\n",
    "            swara_sequence_raw = [get_closest_note(freq, carnatic_frequencies) for freq in segment_data]\n",
    "            \n",
    "            # 2. Simplify the sequence by removing consecutive duplicates\n",
    "            simplified_sequence = []\n",
    "            if swara_sequence_raw:\n",
    "                simplified_sequence.append(swara_sequence_raw[0])\n",
    "                for i in range(1, len(swara_sequence_raw)):\n",
    "                    if swara_sequence_raw[i] != swara_sequence_raw[i-1]:\n",
    "                        simplified_sequence.append(swara_sequence_raw[i])\n",
    "            \n",
    "            if simplified_sequence:\n",
    "                # Convert list to a tuple to make it hashable for the Counter\n",
    "                list_of_sequences.append(tuple(simplified_sequence))\n",
    "\n",
    "        except (ValueError, SyntaxError):\n",
    "            continue\n",
    "\n",
    "    if not list_of_sequences:\n",
    "        print(f\"Could not determine a dominant sequence for cluster {cluster_number}.\"); return\n",
    "\n",
    "    # 3. Count the occurrences of each unique sequence\n",
    "    sequence_counts = Counter(list_of_sequences)\n",
    "    \n",
    "    # 4. The most common sequence becomes the label\n",
    "    most_common_sequence, count = sequence_counts.most_common(1)[0]\n",
    "    final_label = \" \".join(most_common_sequence)\n",
    "    \n",
    "    confidence = (count / len(list_of_sequences)) * 100\n",
    "    print(f\"Cluster {cluster_number}: Determined dominant sequence -> '{final_label}' (Confidence: {confidence:.1f}%)\")\n",
    "    \n",
    "    # Use the existing label_cluster function to save the result\n",
    "    label_cluster(audio_dir, cluster_number, final_label)\n",
    "\n",
    "\n",
    "auto_label_cluster(audio_dir, 26) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed68c117",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
